{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías básicas\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de datos\n",
    "df = pd.read_excel('Iris.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el dataset en conjuntos de entrenamiento y prueba (70% - 30%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(1234)\n",
    "X = df[df.columns[:-1]]\n",
    "Y = df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árbol de decisión de profundidad 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librería\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar el modelo\n",
    "arbol = DecisionTreeClassifier(max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "arbol.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones para el conjunto de prueba\n",
    "y_pred = arbol.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graficación del árbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import graphviz\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer los valores de las clases\n",
    "lista_clases = df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el archivo .dot\n",
    "export_graphviz(arbol, out_file = 'arbol.dot',\n",
    "               feature_names = df.columns[:-1],\n",
    "               class_names = lista_clases,\n",
    "               filled = True,\n",
    "               max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar\n",
    "with open('arbol.dot') as f:\n",
    "    dot_graph = f.read()\n",
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar como imagen PNG\n",
    "import pydot\n",
    "\n",
    "(graph,) = pydot.graph_from_dot_file('arbol.dot')\n",
    "graph.write_png('arbol.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Árbol como texto\n",
    "from sklearn.tree import export_text\n",
    "lista_columnas = list(df.columns[:-1])\n",
    "r = export_text(arbol, max_depth=3, feature_names = lista_columnas)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas (I)\n",
    "## Automáticas\n",
    "*El uso de algunas métricas globales carece de sentido si se tienen varias clases*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, confusion_matrix, recall_score, precision_score, balanced_accuracy_score, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confución\n",
    "CM = confusion_matrix(y_test,y_pred)\n",
    "print('CM = ', CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presición\n",
    "# Como se tienen varias clases es necesario hacer la aclaración del tipo de promedio, en este caso 'micro' cuenta los totales\n",
    "PPV = precision_score(y_test,y_pred, average = 'micro')\n",
    "print('PPV = ', PPV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exactitud\n",
    "ACC = accuracy_score(y_test,y_pred)\n",
    "print('ACC = ', ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensibilidad\n",
    "# Como se tienen varias clases es necesario hacer la aclaración del tipo de promedio, en este caso 'micro' cuenta los totales\n",
    "VPR = recall_score(y_test,y_pred, average = 'micro')\n",
    "print('VPR = ', VPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exactitud balanceada\n",
    "BAC = balanced_accuracy_score(y_test,y_pred)\n",
    "print('BAC = ', BAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kappa de Cohen\n",
    "k = cohen_kappa_score(y_test,y_pred)\n",
    "print('k = ',k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas (II)\n",
    "## Manuales a partir de la matriz de confusión\n",
    "\n",
    "*El uso de algunas métricas globales carece de sentido si se tienen varias clases*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verdaderos positivos y verdaderos negativos\n",
    "#Si se calculan de forma global, no por clase, son los mismos\n",
    "# Suma de elementos de la diagonal de la matriz de confusión\n",
    "# Se utiliza la función trace (traza) de NumPy\n",
    "TP = np.trace(CM)\n",
    "TN = np.trace(CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Falsos positivos y falsos negativos\n",
    "# Si se calcula en forma global, no por clase, los falsos positivos y falsos negativos son los mismos\n",
    "FP = np.sum(CM) - np.trace(CM)\n",
    "FN = np.sum(CM) - np.trace(CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensibilidad\n",
    "VPR_man = TP / (TP + FN)\n",
    "# Especificidad\n",
    "SPC_man = TN / (TN + FP)\n",
    "# Precisión\n",
    "PPV_man = TP / (TP + FP)\n",
    "# Exactitud\n",
    "ACC_man = TP / np.sum(CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('VPR = ', VPR_man)\n",
    "print('SPC = ', SPC_man)\n",
    "print('PPV = ', PPV_man)\n",
    "print('ACC = ', ACC_man)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
